= Executing CQL statements
:page-layout: gcx-full
:secure-connect-bundle-url: https://docs.datastax.com/en/astra-serverless/docs/connect/secure-connect-bundle.html

The sample application executes statements to create a schema and insert some data into the database.

== Prerequisites

* Create an Astra database and {secure-connect-bundle-url}[download your secure connect bundle] that contains connection information such as contact points and certificates.
* Create a xref:connecting-to-astra-python.adoc[connection to Astra].

== Procedure

Retrieving metadata for the cluster is good, but you also want to be able to read and write data to the cluster. The driver lets you execute CQL statements using a session instance that you retrieve from the cluster object. 
You will add code to your client to:

* create tables
* insert data into those tables

[.gcx-hook-connect='34-34']
== Drop a table if it exists

Drop the table if it already exists and you are rewriting the schema.

[.gcx-hook-connect='35-45']
== Create a table

Create a Cassandra Query Language (CQL) table with schema to store data.

[.gcx-hook-connect='47-58']
== Load (insert) data

Execute an INSERT statement to insert data into the table.

[.gcx-hook-connect='63-64']
== Modify the main code

Modify the main code to include calls to the new classes and execute the create and insert.

[.gcx-code-connect] 
[source,Python]
----
#!/usr/bin/env python
# -*- coding: utf-8 -*-

from cassandra.auth import PlainTextAuthProvider
from cassandra.cluster import Cluster

class ConnectionClient:
    SECURE_CONNECT_BUNDLE = "/path/to/secure-connect-driver-demo.zip"
    CLIENT_ID = "client-id"
    CLIENT_SECRET = "client-secret"
    KEYSPACE = "demo"

    def __init__(self):
        self.cluster = None
        self.session = None
    
    def connect(self):
        cloud_config = {
            "secure_connect_bundle" : self.SECURE_CONNECT_BUNDLE
        }
        authProvider = PlainTextAuthProvider(self.CLIENT_ID, self.CLIENT_SECRET)
        self.cluster = Cluster(cloud = cloud_config, auth_provider = authProvider)
        self.session = self.cluster.connect(self.KEYSPACE)
        for host in self.cluster.metadata.all_hosts():
            print(f"{host}")
            
    def close(self):
        self.cluster.shutdown()

class StatementsClient(ConnectionClient):
    def __init__(self):
        super().__init__()
        
    def createSchema(self):
        self.session.execute("DROP TABLE IF EXISTS demo.songs;", timeout = 10.0)
        self.session.execute("""
            CREATE TABLE demo.songs (
                id uuid PRIMARY KEY,
                title text,
                album text,
                artist text,
                tags set<text>,
                data blob
            );
        """)
        print('schema created in demo keyspace')

    def loadData(self):
        self.session.execute("""
            INSERT INTO demo.songs (id, title, album, artist, tags)
            VALUES (
                756716f7-2e54-4715-9f00-91dcbea6cf50,
                'La Petite Tonkinoise',
                'Bye Bye Blackbird',
                'Jos√©phine Baker',
                {'jazz', '2013'}
            );
        """)
        print('data loaded into demo schema')
        
def main():
    client = StatementsClient()
    client.connect()
    client.createSchema()
    client.loadData()
    client.close()

if __name__ == "__main__":
    main()
----

== Result

On the Astra dashboard, connect to the database and select the CQL Console tab.
Issue these two cqlsh commands:
1. USE demo;
2. DESCRIBE KEYSPACE demo;

This result is printed out:

....
CREATE KEYSPACE demo WITH replication = {'class': 'NetworkTopologyStrategy', 'us-east1': '3'} AND durable_writes = true;

CREATE TABLE demo.playlists (
id uuid,
title text,
album text,
artist text,
song_id uuid,
PRIMARY KEY (id, title, album, artist)
) WITH CLUSTERING ORDER BY (title ASC, album ASC, artist ASC)
AND additional_write_policy = '99PERCENTILE'
AND bloom_filter_fp_chance = 0.01
AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}
AND comment = ''
AND compaction = {'class': 'org.apache.cassandra.db.compaction.UnifiedCompactionStrategy'}
AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}
AND crc_check_chance = 1.0
AND default_time_to_live = 0
AND gc_grace_seconds = 864000
AND max_index_interval = 2048
AND memtable_flush_period_in_ms = 0
AND min_index_interval = 128
AND read_repair = 'BLOCKING'
AND speculative_retry = '99PERCENTILE';

CREATE TABLE demo.songs (
id uuid PRIMARY KEY,
album text,
artist text,
data blob,
tags set<text>,
title text
) WITH additional_write_policy = '99PERCENTILE'
AND bloom_filter_fp_chance = 0.01
AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}
AND comment = ''
AND compaction = {'class': 'org.apache.cassandra.db.compaction.UnifiedCompactionStrategy'}
AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}
AND crc_check_chance = 1.0
AND default_time_to_live = 0
AND gc_grace_seconds = 864000
AND max_index_interval = 2048
AND memtable_flush_period_in_ms = 0
AND min_index_interval = 128
AND read_repair = 'BLOCKING'
AND speculative_retry = '99PERCENTILE';
....
